{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# deepsort","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/deepsort/deep_sort_pytorch/')\nfrom deep_sort.deep_sort import DeepSort\nfrom utils.parser import get_config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params can change\n\n# data file\n#mapping_result_df_path = '/kaggle/working/test_mapping.csv'\n# mapping_result_df_path = '/kaggle/input/predeepsort/test_mapping_v2.csv'\n# deep sort\n\nREID_CKPT= \"/kaggle/input/deepsort-data/ckpt.t7\"\n\n# in cascade match, if larger than this dist, just ignore that match\nMAX_DIST= 0.2\n\n# detection conf should be larger than this value\nMIN_CONFIDENCE= 0.3\n\n# value of NMS, = 1 means do nothing\nNMS_MAX_OVERLAP= 1\n\n# max iou, used in iou match\nMAX_IOU_DISTANCE= 1\n\n# how many times not updated, track will be delete, \n# life last, for how many frames\nMAX_AGE= 30\n\n# track to confirmed, you need to have how many hits\nN_INIT= 1\n\n# for each class, largest possible number\nNN_BUDGET= 22","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deepsort_helmets(video_name,\n                     video_data,\n                     video_dir,\n                     plot=False,\n                     plot_frames=[]):\n    \n    # Setup Deepsort \n    deepsort = DeepSort(model_path=REID_CKPT,\n                        max_dist=MAX_DIST,\n                        min_confidence=MIN_CONFIDENCE,\n                        #nms_max_overlap=NMS_MAX_OVERLAP,\n                        max_iou_distance=MAX_IOU_DISTANCE,\n                        max_age=MAX_AGE,\n                        n_init=N_INIT,\n                        nn_budget=NN_BUDGET,\n                        use_cuda=True)\n    \n    # Run through frames.\n    video_data = video_data.sort_values('frame').reset_index(drop=True)\n    one_video_result = []\n    \n    for frame, frame_data in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n        frame_data['x'] = (frame_data['left'] + round(frame_data['width'] / 2))\n        frame_data['y'] = (frame_data['top'] + round(frame_data['height'] / 2))\n        #二维列表\n        xywhs = frame_data[['x','y','width','height']].values\n        \n        #打开视频文件\n        cap = cv2.VideoCapture(f'{video_dir}/{video_name}.mp4')\n        # frame-1 is designed by cv2 library, means read no.of frame = frame\n        #set一些属性 （下一个要解码/捕获的帧基于0索引）\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1)\n        success, image = cap.read()\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        # 不筛选conf 其实mapping的时候已经筛选过一遍了\n        confs = np.ones([len(frame_data),])\n        # 全部都是helment 不分class\n        clss =  np.zeros([len(frame_data),])\n        \n        one_frame_outputs = deepsort.update(xywhs, confs, clss, image)\n        one_frame_deepsort_result = pd.DataFrame(one_frame_outputs, columns=['left','top','right','bottom','track_id','class_id'])\n        \n        if len(one_frame_deepsort_result) > 0:\n            # TODO Fix this messy merge\n            # deepsort的结果 和 detection的结果对应起来，即赋予每个bbox一个traking id\n            #sort_values按多列排序，第一列排好后（内部）第二列也要排\n            frame_data = pd.merge_asof(frame_data.sort_values(['left','top']),\n                                       one_frame_deepsort_result[['left','top','track_id']].sort_values(['left','top']), \n                                       on='left', \n                                       suffixes=('','_deepsort'), #  相同列名的话加后缀\n                                       direction='nearest')\n            \n        one_video_result.append(frame_data)\n    #concat沿特定轴连接pandas对象 （串联起来）\n    one_video_result = pd.concat(one_video_result)\n    \n    return one_video_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_deepsort_label_col(one_video_result):\n    # col has:\n    # video_frame, left, width, top, height, label\n    # video, frame, x, y, top_deepsort, track_id\n    \n    # one_video_result is the return value of deepsort_helments\n    \n    # Find the top occuring label for each deepsort_cluster\n    # value_counts: Return a Series containing counts of unique values.\n    # to_frame: convert series to dataframe\n    # reset_index: Reset the index of the DataFrame, and use the default one instead.\n    # to_dict: Convert the DataFrame to a dictionary.\n#     sortlabel_map = one_video_result.groupby('track_id')['label'].value_counts() \\\n#         .sort_values(ascending=False).to_frame() \\\n#         .rename(columns={'label':'label_count'}) \\\n#         .reset_index() \\\n#         .groupby(['track_id']) \\\n#         .first()['label'].to_dict()\n    \n    # Find the # of times that label appears for the deepsort_cluster.\n#     sortlabelcount_map = one_video_result.groupby('track_id')['label'].value_counts() \\\n#         .sort_values(ascending=False).to_frame() \\\n#         .rename(columns={'label':'label_count'}) \\\n#         .reset_index() \\\n#         .groupby(['track_id']) \\\n#         .first()['label_count'].to_dict()\n    \n    #我写的：不考虑前后帧，只针对某个人track_id(deepsort_cluster)进行分析\n    #选择len_diff最小的label作为可信的label(true_label)\n    #[one_video_result[\"len_diff\"]<1]\n    truelabel_map = one_video_result[one_video_result[\"len_diff\"]<1].groupby('track_id')['label'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'label':'label_count'}) \\\n        .reset_index() \\\n        .groupby(['track_id']) \\\n        .first()['label'].to_dict()\n    \n    one_video_result['label_deepsort'] = one_video_result['track_id'].map(truelabel_map)\n#     one_video_result['label_deepsort'] = one_video_result['track_id'].map(sortlabel_map)\n#     one_video_result['label_count_deepsort'] = one_video_result['track_id'].map(sortlabelcount_map)\n\n    return one_video_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add video and frame columns to submission.\nmapping_result_df['video'] = mapping_result_df['video_frame'].str.split('_').str[:3].str.join('_')\nmapping_result_df['frame'] = mapping_result_df['video_frame'].str.split('_').str[-1].astype('int')\n\nif debug:\n    video_dir = '../input/nfl-health-and-safety-helmet-assignment/train/'\nelse:\n    video_dir = '../input/nfl-health-and-safety-helmet-assignment/test/'\n\n# Loop through test videos and apply. If in debug mode show the score change.\nall_videos_result = []\nall_videos_change_label_result = []\ncount = 0\nfor video_name, video_data in tqdm(mapping_result_df.groupby('video'), total=mapping_result_df['video'].nunique()):\n    print(f'==== {video_name} ====')\n    if debug:\n        # Plot deepsort labels when in debug mode.\n        one_video_result = deepsort_helmets(video_name, video_data, video_dir, plot_frames=[10, 150, 250])\n    else:\n        one_video_result = deepsort_helmets(video_name, video_data, video_dir)\n    #one_video_result.groupby('track_id').apply(lambda x: x.sort_values('len_diff', ascending=False))\n    all_videos_result.append(one_video_result)\n    one_video_change_label_result = add_deepsort_label_col(one_video_result)\n    all_videos_change_label_result.append(one_video_change_label_result)\n#     if debug:\n#         # Score\n#         score_vs_deepsort(myvideo, out, labels)\n        \nmapping_deepsort_result = pd.concat(all_videos_change_label_result).copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### rename submission df","metadata":{}},{"cell_type":"code","source":"ss = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\n# Final Checks\nmapping_deepsort_result['label_deepsort'] = mapping_deepsort_result['label_deepsort'] \\\n    .fillna(mapping_deepsort_result['label'])\nmapping_deepsort_result = mapping_deepsort_result.drop('label', axis=1) \\\n    .rename(columns={'label_deepsort':'label'})[ss.columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop duplicate labels\nmapping_deepsort_result = mapping_deepsort_result.drop_duplicates(subset=[\"video_frame\", \"label\"], keep='first')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping_deepsort_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save final result","metadata":{}},{"cell_type":"code","source":"submission_df_path = '/kaggle/working/submission.csv'\nmapping_deepsort_result.to_csv(submission_df_path, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}