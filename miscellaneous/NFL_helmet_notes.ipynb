{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NFL_helmet_notes.ipynb","provenance":[],"collapsed_sections":["i699tTthXRYj"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"X4KWMu1tSUDD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632213619581,"user_tz":-480,"elapsed":15982,"user":{"displayName":"zz w","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01928120792238499571"}},"outputId":"f1a2a1e1-2572-4ebe-a8ea-d087a8d06197"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r88camusA_Jc","executionInfo":{"status":"ok","timestamp":1632295438735,"user_tz":-480,"elapsed":581,"user":{"displayName":"Junxian Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1Sroux5RZdHZk6WJgx3TYH3Xe8rp6qoAtnpxR=s64","userId":"12554079873176038226"}},"outputId":"1baec185-ee65-42d1-aa55-035edbc55153"},"source":["!mkdir train_local\n","!unzip /content/gdrive/MyDrive/NFL_Helmet/nfl-health-and-safety-helmet-assignment.zip -d train_local/"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open /content/gdrive/MyDrive/NFL_Helmet/nfl-health-and-safety-helmet-assignment.zip, /content/gdrive/MyDrive/NFL_Helmet/nfl-health-and-safety-helmet-assignment.zip.zip or /content/gdrive/MyDrive/NFL_Helmet/nfl-health-and-safety-helmet-assignment.zip.ZIP.\n"]}]},{"cell_type":"markdown","metadata":{"id":"LnHXT03xGLoN"},"source":["# Notes\n","1. Using optimization methods to match helmet boxes to NGS data based on relative distances.\n","2. Tracking of helmets throughout the duration of a play and assigning labels to these tracks.\n","3. Imputing boxes for partially occluded helmets based on the surrounding frames.\n","4. Using computer vision techniques to identify player jersey numbers and pair with helmets."]},{"cell_type":"markdown","metadata":{"id":"dH4_aJ7LHrpN"},"source":["* Goal:A perfect submission would correctly identify the helmet box for every helmet in every frame of video- and assign that helmet the correct player label.\n","Requirement: \n","1. Submission boxes must have at least a 0.35 Intersection over Union (IoU) with the ground truth helmet box.\n","2. Each ground truth helmet box will only be paired with one helmet box per frame in the submitted solution. For each ground truth box, the submitted box with the highest IoU will be considered for scoring.\n","3. No more than 22 helmet predictions per video frame (the maximum number of players participating on field at a time). In some situations, sideline players can be seen in the video footage. Sideline players' helmets are not scored in the grading algorithm and can be ignored. Sideline players will have the helmet labels \"H00\" and \"V00\". Sideline players should not be included in the submission to avoid exceeding the 22-box and unique label constraints.\n","4. A player's helmet label must only be predicted once per video frame, i.e. no duplicated labels per frame.\n","5. All submitted helmet boxes must be unique per video frame, i.e. no identical (left, right, height and width) boxes per frame.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"G4FKqvQLKOm4"},"source":["* Conclusion from dataset\n","1. test videos are subset of train videos\n","2. Total 120 videos 60 for each. Sideline and Endzone video pair for every plays!\n","3. 25 plays out of 60 doesn't match and the difference is mostly 1 frame but there are 7 frame difference also\n","4. 57584_000336_Sideline_0 has frame 0\n","5. 50games 60plays 52142 frames (frames means images) 41 games has only 1 play\n","，8 games has 2 plays， 1 game has 3 plays [train_labels.csv]\n","6. 196 players exist. Not sure they are all unique Home has 98 players and 1, 45 number player only exist at home visitor has 98 players and 9, 43 number player only exist at visitor\n","7. 25 out of 60 plays include sideline player (need to exclude) 23 players mostly shown. And 25 Sideline videos, 5 Endzone videos shown sideline players. It's easy to see sideline players when the camera is at the side of sideline\n","8. 5928 is the biggest helmet size shown in the video and occure when the camera is zooming. 9 is the smallest helmets sizeMostly the helmet size are around 150\n","9. Definitive impact is subset of Impacts and all types of impact could be definitive impact Definitive impact moment is 500 times smaller than normal impact\n","10. 50 games 60 plays 15180 frames (frames means images) min 113 max 456(TIME)(player tracking.csv) \n","11. ball snap is the starting point of the game, All plays are recorded before the ball snap!\n","12. Mostly 22 players are tracked but in some frames less than 22 are tracked, There are 6 plays that are not consistent.The ID is 109, 336, 350, 1242, 2546, 4152\n","13. all the track time is longer than train videos and mostly 3 times longer! Some tracking information is approximately 6 times longer!\n","14. It become more consistent when considering only the time period of train videos. But still 3 tracking information is not consistent. We need to think how to impute this missing data. Considering the whole tracking - 109, 336, 350, 1242, 2546, 4152 Only for the video time period - 109, 336, 4152\n","15. [image_labels.csv] can be used to train bbox\n","16. 82 bbox was predicted in max for 1 frame, 2 bbox was predicted in max for 1 fram"]},{"cell_type":"markdown","metadata":{"id":"L6KRVjyf4aGO"},"source":["* so what we need to do?\n","1. train helmet bbox with object detection with train_label.csv(change categories to helmet) + image_label.csv, which can update from baseline_helmet [we can try yolov4,v5,x,r,PPyolo etc in this part]\n","2. map helmet data to tracking data with player number [we can try deepsort or metric learning,etc]\n","3. test on testset frames to generate sumbit.csv [a definitive impact * more weight]\n"]},{"cell_type":"markdown","metadata":{"id":"y-PGmSWzGSnj"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"djSgK3bFCPYn"},"source":["import os\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from PIL import Image, ImageDraw\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bWO8P4hPTqLF","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"error","timestamp":1632213622450,"user_tz":-480,"elapsed":517,"user":{"displayName":"zz w","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01928120792238499571"}},"outputId":"4d420ba7-6204-4049-8396-57bae5963b4f"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pylab as plt\n","\n","# Read in data files\n","BASE_DIR = './train_local'\n","\n","# Labels and sample submission\n","labels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\n","ss = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n","\n","# Player tracking data\n","tr_tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\n","te_tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n","\n","# Baseline helmet detection labels\n","tr_helmets = pd.read_csv(f'{BASE_DIR}/train_baseline_helmets.csv')\n","te_helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n","\n","# Extra image labels\n","# Trained images using images_labels.csv and predict the train, test\n","# The prediction result is [train/test]_baseline_helmets.csv\n","# No player information is included\n","\n","img_labels = pd.read_csv(f'{BASE_DIR}/image_labels.csv')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-0a67bd4efe93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Labels and sample submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{BASE_DIR}/train_labels.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{BASE_DIR}/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_local/train_labels.csv'"]}]},{"cell_type":"markdown","metadata":{"id":"ycXnAMejURmt"},"source":["# check data"]},{"cell_type":"code","metadata":{"id":"aYChtzbiUKQ2"},"source":["#This file is only available for the training dataset and provides the ground truth for the 120 training videos.\n","labels[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MKTQgdkVNiN"},"source":["ss[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fh_o6Eq6UOC6"},"source":["#contain the tracking data for all players on the field during the play.\n","tr_tracking[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7qjVoSgUVW5"},"source":["#imperfect helmet location\n","tr_helmets[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jL_U1hP19oFq"},"source":["te_helmets[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGNSfOuoUr_r"},"source":["# contains helmet boxes for random frames in videos.\n","img_labels[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i699tTthXRYj"},"source":["# Evaluate Function"]},{"cell_type":"code","metadata":{"id":"Uong3ZdeYOtG"},"source":["from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import numpy as np\n","\n","\n","class NFLAssignmentScorer:\n","    def __init__(\n","        self,\n","        labels_df: pd.DataFrame = None,\n","        labels_csv=\"train_labels.csv\",\n","        check_constraints=True,\n","        weight_col=\"isDefinitiveImpact\",\n","        impact_weight=1000,\n","        iou_threshold=0.35,\n","        remove_sideline=True,\n","    ):\n","        \"\"\"\n","        Helper class for grading submissions in the\n","        2021 Kaggle Competition for helmet assignment.\n","        Version 1.0\n","        https://www.kaggle.com/robikscube/nfl-helmet-assignment-getting-started-guide\n","\n","        Use:\n","        ```\n","        scorer = NFLAssignmentScorer(labels)\n","        scorer.score(submission_df)\n","\n","        or\n","\n","        scorer = NFLAssignmentScorer(labels_csv='labels.csv')\n","        scorer.score(submission_df)\n","        ```\n","\n","        Args:\n","            labels_df (pd.DataFrame, optional):\n","                Dataframe containing theground truth label boxes.\n","            labels_csv (str, optional): CSV of the ground truth label.\n","            check_constraints (bool, optional): Tell the scorer if it\n","                should check the submission file to meet the competition\n","                constraints. Defaults to True.\n","            weight_col (str, optional):\n","                Column in the labels DataFrame used to applying the scoring\n","                weight.\n","            impact_weight (int, optional):\n","                The weight applied to impacts in the scoring metrics.\n","                Defaults to 1000.\n","            iou_threshold (float, optional):\n","                The minimum IoU allowed to correctly pair a ground truth box\n","                with a label. Defaults to 0.35.\n","            remove_sideline (bool, optional):\n","                Remove slideline players from the labels DataFrame\n","                before scoring.\n","        \"\"\"\n","        if labels_df is None:\n","            # Read label from CSV\n","            if labels_csv is None:\n","                raise Exception(\"labels_df or labels_csv must be provided\")\n","            else:\n","                self.labels_df = pd.read_csv(labels_csv)\n","        else:\n","            self.labels_df = labels_df.copy()\n","        if remove_sideline:\n","            self.labels_df = (\n","                self.labels_df.query(\"isSidelinePlayer == False\")\n","                .reset_index(drop=True)\n","                .copy()\n","            )\n","        self.impact_weight = impact_weight\n","        self.check_constraints = check_constraints\n","        self.weight_col = weight_col\n","        self.iou_threshold = iou_threshold\n","\n","    def check_submission(self, sub):\n","        \"\"\"\n","        Checks that the submission meets all the requirements.\n","\n","        1. No more than 22 Boxes per frame.\n","        2. Only one label prediction per video/frame\n","        3. No duplicate boxes per frame.\n","\n","        Args:\n","            sub : submission dataframe.\n","\n","        Returns:\n","            True -> Passed the tests\n","            False -> Failed the test\n","        \"\"\"\n","        # Maximum of 22 boxes per frame.\n","        max_box_per_frame = sub.groupby([\"video_frame\"])[\"label\"].count().max()\n","        if max_box_per_frame > 22:\n","            print(\"Has more than 22 boxes in a single frame\")\n","            return False\n","        # Only one label allowed per frame.\n","        has_duplicate_labels = sub[[\"video_frame\", \"label\"]].duplicated().any()\n","        if has_duplicate_labels:\n","            print(\"Has duplicate labels\")\n","            return False\n","        # Check for unique boxes\n","        has_duplicate_boxes = (\n","            sub[[\"video_frame\", \"left\", \"width\", \"top\", \"height\"]].duplicated().any()\n","        )\n","        if has_duplicate_boxes:\n","            print(\"Has duplicate boxes\")\n","            return False\n","        return True\n","\n","    def add_xy(self, df):\n","        \"\"\"\n","        Adds `x1`, `x2`, `y1`, and `y2` columns necessary for computing IoU.\n","\n","        Note - for pixel math, 0,0 is the top-left corner so box orientation\n","        defined as right and down (height)\n","        \"\"\"\n","\n","        df[\"x1\"] = df[\"left\"]\n","        df[\"x2\"] = df[\"left\"] + df[\"width\"]\n","        df[\"y1\"] = df[\"top\"]\n","        df[\"y2\"] = df[\"top\"] + df[\"height\"]\n","        return df\n","\n","    def merge_sub_labels(self, sub, labels, weight_col=\"isDefinitiveImpact\"):\n","        \"\"\"\n","        Perform an outer join between submission and label.\n","        Creates a `sub_label` dataframe which stores the matched label for each submission box.\n","        Ground truth values are given the `_gt` suffix, submission values are given `_sub` suffix.\n","        \"\"\"\n","        sub = sub.copy()\n","        labels = labels.copy()\n","\n","        sub = self.add_xy(sub)\n","        labels = self.add_xy(labels)\n","\n","        base_columns = [\n","            \"label\",\n","            \"video_frame\",\n","            \"x1\",\n","            \"x2\",\n","            \"y1\",\n","            \"y2\",\n","            \"left\",\n","            \"width\",\n","            \"top\",\n","            \"height\",\n","        ]\n","\n","        sub_labels = sub[base_columns].merge(\n","            labels[base_columns + [weight_col]],\n","            on=[\"video_frame\"],\n","            how=\"right\",\n","            suffixes=(\"_sub\", \"_gt\"),\n","        )\n","        return sub_labels\n","\n","    def get_iou_df(self, df):\n","        \"\"\"\n","        This function computes the IOU of submission (sub)\n","        bounding boxes against the ground truth boxes (gt).\n","        \"\"\"\n","        df = df.copy()\n","\n","        # 1. get the coordinate of inters\n","        df[\"ixmin\"] = df[[\"x1_sub\", \"x1_gt\"]].max(axis=1)\n","        df[\"ixmax\"] = df[[\"x2_sub\", \"x2_gt\"]].min(axis=1)\n","        df[\"iymin\"] = df[[\"y1_sub\", \"y1_gt\"]].max(axis=1)\n","        df[\"iymax\"] = df[[\"y2_sub\", \"y2_gt\"]].min(axis=1)\n","\n","        df[\"iw\"] = np.maximum(df[\"ixmax\"] - df[\"ixmin\"] + 1, 0.0)\n","        df[\"ih\"] = np.maximum(df[\"iymax\"] - df[\"iymin\"] + 1, 0.0)\n","\n","        # 2. calculate the area of inters\n","        df[\"inters\"] = df[\"iw\"] * df[\"ih\"]\n","\n","        # 3. calculate the area of union\n","        df[\"uni\"] = (\n","            (df[\"x2_sub\"] - df[\"x1_sub\"] + 1) * (df[\"y2_sub\"] - df[\"y1_sub\"] + 1)\n","            + (df[\"x2_gt\"] - df[\"x1_gt\"] + 1) * (df[\"y2_gt\"] - df[\"y1_gt\"] + 1)\n","            - df[\"inters\"]\n","        )\n","        # print(uni)\n","        # 4. calculate the overlaps between pred_box and gt_box\n","        df[\"iou\"] = df[\"inters\"] / df[\"uni\"]\n","\n","        return df.drop(\n","            [\"ixmin\", \"ixmax\", \"iymin\", \"iymax\", \"iw\", \"ih\", \"inters\", \"uni\"], axis=1\n","        )\n","\n","    def filter_to_top_label_match(self, sub_labels):\n","        \"\"\"\n","        Ensures ground truth boxes are only linked to the box\n","        in the submission file with the highest IoU.\n","        \"\"\"\n","        return (\n","            sub_labels.sort_values(\"iou\", ascending=False)\n","            .groupby([\"video_frame\", \"label_gt\"])\n","            .first()\n","            .reset_index()\n","        )\n","\n","    def add_isCorrect_col(self, sub_labels):\n","        \"\"\"\n","        Adds True/False column if the ground truth label\n","        and submission label are identical\n","        \"\"\"\n","        sub_labels[\"isCorrect\"] = (\n","            sub_labels[\"label_gt\"] == sub_labels[\"label_sub\"]\n","        ) & (sub_labels[\"iou\"] >= self.iou_threshold)\n","        return sub_labels\n","\n","    def calculate_metric_weighted(\n","        self, sub_labels, weight_col=\"isDefinitiveImpact\", weight=1000\n","    ):\n","        \"\"\"\n","        Calculates weighted accuracy score metric.\n","        \"\"\"\n","        sub_labels[\"weight\"] = sub_labels.apply(\n","            lambda x: weight if x[weight_col] else 1, axis=1\n","        )\n","        y_pred = sub_labels[\"isCorrect\"].values\n","        y_true = np.ones_like(y_pred)\n","        weight = sub_labels[\"weight\"]\n","        return accuracy_score(y_true, y_pred, sample_weight=weight)\n","\n","    def score(self, sub, labels_df=None, drop_extra_cols=True):\n","        \"\"\"\n","        Scores the submission file against the labels.\n","\n","        Returns the evaluation metric score for the helmet\n","        assignment kaggle competition.\n","\n","        If `check_constraints` is set to True, will return -999 if the\n","            submission fails one of the submission constraints.\n","        \"\"\"\n","        if labels_df is None:\n","            labels_df = self.labels_df.copy()\n","\n","        if self.check_constraints:\n","            if not self.check_submission(sub):\n","                return -999\n","        sub_labels = self.merge_sub_labels(sub, labels_df, self.weight_col)\n","        sub_labels = self.get_iou_df(sub_labels).copy()\n","        sub_labels = self.filter_to_top_label_match(sub_labels).copy()\n","        sub_labels = self.add_isCorrect_col(sub_labels)\n","        score = self.calculate_metric_weighted(\n","            sub_labels, self.weight_col, self.impact_weight\n","        )\n","        # Keep `sub_labels for review`\n","        if drop_extra_cols:\n","            drop_cols = [\n","                \"x1_sub\",\n","                \"x2_sub\",\n","                \"y1_sub\",\n","                \"y2_sub\",\n","                \"x1_gt\",\n","                \"x2_gt\",\n","                \"y1_gt\",\n","                \"y2_gt\",\n","            ]\n","            sub_labels = sub_labels.drop(drop_cols, axis=1)\n","        self.sub_labels = sub_labels\n","        return score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Voy6E-rKW7d3"},"source":["SUB_COLUMNS = ss.columns # Expected submission columns\n","scorer = NFLAssignmentScorer(labels)\n","\n","# Score the sample submission\n","ss_score = scorer.score(ss)\n","print(f'Sample submission scores: {ss_score:0.4f}')\n","\n","# Score a submission with only impacts\n","perfect_impacts = labels.query('isDefinitiveImpact == True and isSidelinePlayer == False')\n","imp_score = scorer.score(perfect_impacts)\n","print(f'A submission with perfect predictions only for impacts scores: {imp_score:0.4f}')\n","\n","# Score a submission with only non-impacts\n","perfect_nonimpacts = labels.query('isDefinitiveImpact == False and isSidelinePlayer == False')\n","nonimp_score = scorer.score(perfect_nonimpacts)\n","print(f'A submission with perfect predictions only for non-impacts scores: {nonimp_score:0.4f}')\n","\n","# Score a perfect submission\n","perfect_train = labels.query('isSidelinePlayer == False')[SUB_COLUMNS].copy()\n","perfect_score = scorer.score(perfect_train)\n","print(f'A perfrect training submission scores: {perfect_score:0.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxGVsoQLYY-C"},"source":["scorer.sub_labels.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZMeXW1KJT85"},"source":["# The sample submission meets these requirements.\n","check_submission(ss)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4EzxQ4AlaukP"},"source":["# baseline"]},{"cell_type":"code","metadata":{"id":"Pd45BoMJawLR"},"source":["import os\n","import cv2\n","import subprocess\n","from IPython.core.display import Video, display\n","import pandas as pd\n","\n","\n","def video_with_baseline_boxes(\n","    video_path: str, baseline_boxes: pd.DataFrame, gt_labels: pd.DataFrame, verbose=True\n",") -> str:\n","    \"\"\"\n","    Annotates a video with both the baseline model boxes and ground truth boxes.\n","    Baseline model prediction confidence is also displayed.\n","    \"\"\"\n","    VIDEO_CODEC = \"MP4V\"\n","    HELMET_COLOR = (0, 0, 0)  # Black\n","    BASELINE_COLOR = (255, 255, 255)  # White\n","    IMPACT_COLOR = (0, 0, 255)  # Red\n","    video_name = os.path.basename(video_path).replace(\".mp4\", \"\")\n","    if verbose:\n","        print(f\"Running for {video_name}\")\n","    baseline_boxes = baseline_boxes.copy()\n","    gt_labels = gt_labels.copy()\n","\n","    baseline_boxes[\"video\"] = (\n","        baseline_boxes[\"video_frame\"].str.split(\"_\").str[:3].str.join(\"_\")\n","    )\n","    gt_labels[\"video\"] = gt_labels[\"video_frame\"].str.split(\"_\").str[:3].str.join(\"_\")\n","    baseline_boxes[\"frame\"] = (\n","        baseline_boxes[\"video_frame\"].str.split(\"_\").str[-1].astype(\"int\")\n","    )\n","    gt_labels[\"frame\"] = gt_labels[\"video_frame\"].str.split(\"_\").str[-1].astype(\"int\")\n","\n","    vidcap = cv2.VideoCapture(video_path)\n","    fps = vidcap.get(cv2.CAP_PROP_FPS)\n","    width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    output_path = \"labeled_\" + video_name + \".mp4\"\n","    tmp_output_path = \"tmp_\" + output_path\n","    output_video = cv2.VideoWriter(\n","        tmp_output_path, cv2.VideoWriter_fourcc(*VIDEO_CODEC), fps, (width, height)\n","    )\n","    frame = 0\n","    while True:\n","        it_worked, img = vidcap.read()\n","        if not it_worked:\n","            break\n","        # We need to add 1 to the frame count to match the label frame index\n","        # that starts at 1\n","        frame += 1\n","\n","        # Let's add a frame index to the video so we can track where we are\n","        img_name = f\"{video_name}_frame{frame}\"\n","        cv2.putText(\n","            img,\n","            img_name,\n","            (0, 50),\n","            cv2.FONT_HERSHEY_SIMPLEX,\n","            1.0,\n","            HELMET_COLOR,\n","            thickness=2,\n","        )\n","\n","        # Now, add the boxes\n","        boxes = baseline_boxes.query(\"video == @video_name and frame == @frame\")\n","        if len(boxes) == 0:\n","            print(\"Boxes incorrect\")\n","            return\n","        for box in boxes.itertuples(index=False):\n","            cv2.rectangle(\n","                img,\n","                (box.left, box.top),\n","                (box.left + box.width, box.top + box.height),\n","                BASELINE_COLOR,\n","                thickness=1,\n","            )\n","            cv2.putText(\n","                img,\n","                f\"{box.conf:0.2}\",\n","                (box.left, max(0, box.top - 5)),\n","                cv2.FONT_HERSHEY_SIMPLEX,\n","                0.5,\n","                BASELINE_COLOR,\n","                thickness=1,\n","            )\n","\n","        boxes = gt_labels.query(\"video == @video_name and frame == @frame\")\n","        if len(boxes) == 0:\n","            print(\"Boxes incorrect\")\n","            return\n","        for box in boxes.itertuples(index=False):\n","            # Filter for definitive head impacts and turn labels red\n","            if box.isDefinitiveImpact == True:\n","                color, thickness = IMPACT_COLOR, 3\n","            else:\n","                color, thickness = HELMET_COLOR, 1\n","            cv2.rectangle(\n","                img,\n","                (box.left, box.top),\n","                (box.left + box.width, box.top + box.height),\n","                color,\n","                thickness=thickness,\n","            )\n","            cv2.putText(\n","                img,\n","                box.label,\n","                (box.left + 1, max(0, box.top - 20)),\n","                cv2.FONT_HERSHEY_SIMPLEX,\n","                0.5,\n","                color,\n","                thickness=1,\n","            )\n","\n","        output_video.write(img)\n","    output_video.release()\n","    # Not all browsers support the codec, we will re-load the file at tmp_output_path\n","    # and convert to a codec that is more broadly readable using ffmpeg\n","    if os.path.exists(output_path):\n","        os.remove(output_path)\n","    subprocess.run(\n","        [\n","            \"ffmpeg\",\n","            \"-i\",\n","            tmp_output_path,\n","            \"-crf\",\n","            \"18\",\n","            \"-preset\",\n","            \"veryfast\",\n","            \"-vcodec\",\n","            \"libx264\",\n","            output_path,\n","        ]\n","    )\n","    os.remove(tmp_output_path)\n","\n","    return output_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPZ2z4KX7KOt"},"source":["# !pip install -U kora\n","from kora.drive import upload_public\n","url = upload_public('train_local/train/57584_000336_Sideline.mp4')\n","# then display it\n","from IPython.display import HTML\n","HTML(f\"\"\"<video src={url} width=500 controls/>\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mo96G9935SgE"},"source":["example_video = './train_local/train/57584_000336_Sideline.mp4'\n","output_video = video_with_baseline_boxes(example_video,\n","                          tr_helmets, labels)\n","\n","frac = 0.65 # scaling factor for display"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wkfYRdpq8h5k"},"source":["display(Video(data=output_video,\n","              embed=True,)\n","       )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2wZm8Oi4983x"},"source":["# NGS tracking\n","1. NGS data is sampled at a rate of 10Hz, while videos are sampled at roughly 59.94Hz.\n","2. NGS data and videos can be approximately synced by linking the NGS data where event == \"ball_snap\" to the 10th frame of the video (approximately syncronized to the ball snap in the video).\n","3. The NGS data and the orientation of the video cameras are not consistent. Your solution must account for matching the orientation of the video angle relative to the NGS data."]},{"cell_type":"code","metadata":{"id":"F7qccXjw9zce"},"source":["NGS data is sampled at a rate of 10Hz, while videos are sampled at roughly 59.94Hz.\n","NGS data and videos can be approximately synced by linking the NGS data where event == \"ball_snap\" to the 10th frame of the video (approximately syncronized to the ball snap in the video).\n","The NGS data and the orientation of the video cameras are not consistent. Your solution must account for matching the orientation of the video angle relative to the NGS data."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQopx29h-MHA"},"source":["def add_track_features(tracks, fps=59.94, snap_frame=10):\n","    \"\"\"\n","    Add column features helpful for syncing with video data.\n","    \"\"\"\n","    tracks = tracks.copy()\n","    tracks[\"game_play\"] = (\n","        tracks[\"gameKey\"].astype(\"str\")\n","        + \"_\"\n","        + tracks[\"playID\"].astype(\"str\").str.zfill(6)\n","    )\n","    tracks[\"time\"] = pd.to_datetime(tracks[\"time\"])\n","    snap_dict = (\n","        tracks.query('event == \"ball_snap\"')\n","        .groupby(\"game_play\")[\"time\"]\n","        .first()\n","        .to_dict()\n","    )\n","    tracks[\"snap\"] = tracks[\"game_play\"].map(snap_dict)\n","    tracks[\"isSnap\"] = tracks[\"snap\"] == tracks[\"time\"]\n","    tracks[\"team\"] = tracks[\"player\"].str[0].replace(\"H\", \"Home\").replace(\"V\", \"Away\")\n","    tracks[\"snap_offset\"] = (tracks[\"time\"] - tracks[\"snap\"]).astype(\n","        \"timedelta64[ms]\"\n","    ) / 1_000\n","    # Estimated video frame\n","    tracks[\"est_frame\"] = (\n","        ((tracks[\"snap_offset\"] * fps) + snap_frame).round().astype(\"int\")\n","    )\n","    return tracks\n","\n","\n","tr_tracking = add_track_features(tr_tracking)\n","te_tracking = add_track_features(te_tracking)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUOER8iP-MnJ"},"source":["import matplotlib.patches as patches\n","import matplotlib.pylab as plt\n","\n","def create_football_field(\n","    linenumbers=True,\n","    endzones=True,\n","    highlight_line=False,\n","    highlight_line_number=50,\n","    highlighted_name=\"Line of Scrimmage\",\n","    fifty_is_los=False,\n","    figsize=(12, 6.33),\n","    field_color=\"lightgreen\",\n","    ez_color='forestgreen',\n","    ax=None,\n","):\n","    \"\"\"\n","    Function that plots the football field for viewing plays.\n","    Allows for showing or hiding endzones.\n","    \"\"\"\n","    rect = patches.Rectangle(\n","        (0, 0),\n","        120,\n","        53.3,\n","        linewidth=0.1,\n","        edgecolor=\"r\",\n","        facecolor=field_color,\n","        zorder=0,\n","    )\n","\n","    if ax is None:\n","        fig, ax = plt.subplots(1, figsize=figsize)\n","    ax.add_patch(rect)\n","\n","    plt.plot([10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n","              80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n","             [0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3,\n","              53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n","             color='black')\n","\n","    if fifty_is_los:\n","        ax.plot([60, 60], [0, 53.3], color=\"gold\")\n","        ax.text(62, 50, \"<- Player Yardline at Snap\", color=\"gold\")\n","    # Endzones\n","    if endzones:\n","        ez1 = patches.Rectangle(\n","            (0, 0),\n","            10,\n","            53.3,\n","            linewidth=0.1,\n","            edgecolor=\"black\",\n","            facecolor=ez_color,\n","            alpha=0.6,\n","            zorder=0,\n","        )\n","        ez2 = patches.Rectangle(\n","            (110, 0),\n","            120,\n","            53.3,\n","            linewidth=0.1,\n","            edgecolor=\"black\",\n","            facecolor=ez_color,\n","            alpha=0.6,\n","            zorder=0,\n","        )\n","        ax.add_patch(ez1)\n","        ax.add_patch(ez2)\n","    ax.axis(\"off\")\n","    if linenumbers:\n","        for x in range(20, 110, 10):\n","            numb = x\n","            if x > 50:\n","                numb = 120 - x\n","            ax.text(\n","                x,\n","                5,\n","                str(numb - 10),\n","                horizontalalignment=\"center\",\n","                fontsize=20,  # fontname='Arial',\n","                color=\"black\",\n","            )\n","            ax.text(\n","                x - 0.95,\n","                53.3 - 5,\n","                str(numb - 10),\n","                horizontalalignment=\"center\",\n","                fontsize=20,  # fontname='Arial',\n","                color=\"black\",\n","                rotation=180,\n","            )\n","    if endzones:\n","        hash_range = range(11, 110)\n","    else:\n","        hash_range = range(1, 120)\n","\n","    for x in hash_range:\n","        ax.plot([x, x], [0.4, 0.7], color=\"black\")\n","        ax.plot([x, x], [53.0, 52.5], color=\"black\")\n","        ax.plot([x, x], [22.91, 23.57], color=\"black\")\n","        ax.plot([x, x], [29.73, 30.39], color=\"black\")\n","\n","    if highlight_line:\n","        hl = highlight_line_number + 10\n","        ax.plot([hl, hl], [0, 53.3], color=\"yellow\")\n","        ax.text(hl + 2, 50, \"<- {}\".format(highlighted_name), color=\"yellow\")\n","\n","    border = patches.Rectangle(\n","        (-5, -5),\n","        120 + 10,\n","        53.3 + 10,\n","        linewidth=0.1,\n","        edgecolor=\"orange\",\n","        facecolor=\"white\",\n","        alpha=0,\n","        zorder=0,\n","    )\n","    ax.add_patch(border)\n","    ax.set_xlim((0, 120))\n","    ax.set_ylim((0, 53.3))\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dm7VrY9u-TH-"},"source":["game_play = \"57584_000336\"\n","example_tracks = tr_tracking.query(\"game_play == @game_play and isSnap == True\")\n","ax = create_football_field()\n","for team, d in example_tracks.groupby(\"team\"):\n","    ax.scatter(d[\"x\"], d[\"y\"], label=team, s=65, lw=1, edgecolors=\"black\", zorder=5)\n","ax.legend().remove()\n","ax.set_title(f\"Tracking data for {game_play}: at snap\", fontsize=15)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcJPvUUfB1-V"},"source":["import plotly.express as px\n","import plotly.graph_objects as go\n","import plotly\n","\n","\n","def add_plotly_field(fig):\n","    # Reference https://www.kaggle.com/ammarnassanalhajali/nfl-big-data-bowl-2021-animating-players\n","    fig.update_traces(marker_size=20)\n","    \n","    fig.update_layout(paper_bgcolor='#29a500', plot_bgcolor='#29a500', font_color='white',\n","        width = 800,\n","        height = 600,\n","        title = \"\",\n","        \n","        xaxis = dict(\n","        nticks = 10,\n","        title = \"\",\n","        visible=False\n","        ),\n","        \n","        yaxis = dict(\n","        scaleanchor = \"x\",\n","        title = \"Temp\",\n","        visible=False\n","        ),\n","        showlegend= True,\n","  \n","        annotations=[\n","       dict(\n","            x=-5,\n","            y=26.65,\n","            xref=\"x\",\n","            yref=\"y\",\n","            text=\"ENDZONE\",\n","            font=dict(size=16,color=\"#e9ece7\"),\n","            align='center',\n","            showarrow=False,\n","            yanchor='middle',\n","            textangle=-90\n","        ),\n","        dict(\n","            x=105,\n","            y=26.65,\n","            xref=\"x\",\n","            yref=\"y\",\n","            text=\"ENDZONE\",\n","            font=dict(size=16,color=\"#e9ece7\"),\n","            align='center',\n","            showarrow=False,\n","            yanchor='middle',\n","            textangle=90\n","        )]  \n","        ,\n","        legend=dict(\n","        traceorder=\"normal\",\n","        font=dict(family=\"sans-serif\",size=12),\n","        \n","        orientation=\"h\",\n","        yanchor=\"bottom\",\n","        y=1.00,\n","        xanchor=\"center\",\n","        x=0.5\n","        ),\n","    )\n","    ####################################################\n","        \n","    fig.add_shape(type=\"rect\", x0=-10, x1=0,  y0=0, y1=53.3,line=dict(color=\"#c8ddc0\",width=3),fillcolor=\"#217b00\" ,layer=\"below\")\n","    fig.add_shape(type=\"rect\", x0=100, x1=110, y0=0, y1=53.3,line=dict(color=\"#c8ddc0\",width=3),fillcolor=\"#217b00\" ,layer=\"below\")\n","    for x in range(0, 100, 10):\n","        fig.add_shape(type=\"rect\", x0=x,   x1=x+10, y0=0, y1=53.3,line=dict(color=\"#c8ddc0\",width=3),fillcolor=\"#29a500\" ,layer=\"below\")\n","    for x in range(0, 100, 1):\n","        fig.add_shape(type=\"line\",x0=x, y0=1, x1=x, y1=2,line=dict(color=\"#c8ddc0\",width=2),layer=\"below\")\n","    for x in range(0, 100, 1):\n","        fig.add_shape(type=\"line\",x0=x, y0=51.3, x1=x, y1=52.3,line=dict(color=\"#c8ddc0\",width=2),layer=\"below\")\n","    \n","    for x in range(0, 100, 1):\n","        fig.add_shape(type=\"line\",x0=x, y0=20.0, x1=x, y1=21,line=dict(color=\"#c8ddc0\",width=2),layer=\"below\")\n","    for x in range(0, 100, 1):\n","        fig.add_shape(type=\"line\",x0=x, y0=32.3, x1=x, y1=33.3,line=dict(color=\"#c8ddc0\",width=2),layer=\"below\")\n","    \n","    \n","    fig.add_trace(go.Scatter(\n","    x=[2,10,20,30,40,50,60,70,80,90,98], y=[5,5,5,5,5,5,5,5,5,5,5],\n","    text=[\"G\",\"1 0\",\"2 0\",\"3 0\",\"4 0\",\"5 0\",\"4 0\",\"3 0\",\"2 0\",\"1 0\",\"G\"],\n","    mode=\"text\",\n","    textfont=dict(size=20,family=\"Arail\"),\n","    showlegend=False,\n","    ))\n","    \n","    fig.add_trace(go.Scatter(\n","    x=[2,10,20,30,40,50,60,70,80,90,98], y=[48.3,48.3,48.3,48.3,48.3,48.3,48.3,48.3,48.3,48.3,48.3],\n","    text=[\"G\",\"1 0\",\"2 0\",\"3 0\",\"4 0\",\"5 0\",\"4 0\",\"3 0\",\"2 0\",\"1 0\",\"G\"],\n","    mode=\"text\",\n","    textfont=dict(size=20,family=\"Arail\"),\n","    showlegend=False,\n","    ))\n","    \n","    return fig\n","\n","tr_tracking[\"track_time_count\"] = (\n","    tr_tracking.sort_values(\"time\")\n","    .groupby(\"game_play\")[\"time\"]\n","    .rank(method=\"dense\")\n","    .astype(\"int\")\n",")\n","\n","fig = px.scatter(\n","    tr_tracking.query(\"game_play == @game_play\"),\n","    x=\"x\",\n","    y=\"y\",\n","    range_x=[-10, 110],\n","    range_y=[-10, 53.3],\n","    hover_data=[\"player\", \"s\", \"a\", \"dir\"],\n","    color=\"team\",\n","    animation_frame=\"track_time_count\",\n","    text=\"player\",\n",")\n","\n","fig.update_traces(textfont_size=10)\n","fig = add_plotly_field(fig)\n","fig.show(renderer=\"colab\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HZl21qqoC6D6"},"source":["# submission"]},{"cell_type":"code","metadata":{"id":"PszRx7CpEayR"},"source":["def random_label_submission(helmets, tracks):\n","    \"\"\"\n","    Creates a baseline submission with randomly assigned helmets\n","    based on the top 22 most confident baseline helmet boxes for\n","    a frame.\n","    \"\"\"\n","    # Take up to 22 helmets per frame based on confidence:\n","    helm_22 = (\n","        helmets.sort_values(\"conf\", ascending=False)\n","        .groupby(\"video_frame\")\n","        .head(22)\n","        .sort_values(\"video_frame\")\n","        .reset_index(drop=True)\n","        .copy()\n","    )\n","    # Identify player label choices for each game_play\n","    game_play_choices = tracks.groupby([\"game_play\"])[\"player\"].unique().to_dict()\n","    # Loop through frames and randomly assign boxes\n","    ds = []\n","    helm_22[\"label\"] = np.nan\n","    for video_frame, data in helm_22.groupby(\"video_frame\"):\n","        game_play = video_frame[:12]\n","        choices = game_play_choices[game_play]\n","        np.random.shuffle(choices)\n","        data[\"label\"] = choices[: len(data)]\n","        ds.append(data)\n","    submission = pd.concat(ds)\n","    return submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaZYIzvUEhrz"},"source":["train_submission = random_label_submission(tr_helmets, tr_tracking)\n","scorer = NFLAssignmentScorer(labels)\n","baseline_score = scorer.score(train_submission)\n","print(f\"The score of random labels on the training set is {baseline_score:0.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zb0XU0ZEkDj"},"source":["te_tracking = add_track_features(te_tracking)\n","random_submission = random_label_submission(te_helmets, te_tracking)\n","# Check to make sure it meets the submission requirements.\n","assert check_submission(random_submission)\n","random_submission[ss.columns].to_csv(\"submission.csv\", index=False)"],"execution_count":null,"outputs":[]}]}